# ZFNet
#翻译：https://blog.csdn.net/qq_31531635/article/details/71104334

### 概要

由于AlexNet的提出，大型卷积网络开始变得流行起来
但是人们对于网络究竟为什么能表现的这么好?以及怎么样能变得更好尚不清楚?
因此为了针对上述两个问题，提出了一个新颖的可视化技术来一窥中间特征层的功能以及分类的操作

### 亮点

1.翻卷积，将每一层的输出重新映射到像素空间
方法：
1)反池化 ，池化过程不可逆，但是我们可以记下池化区域中最大值的位置，反池化时直接返还到相同位置
2)修正线性单元，不管是向前传，还是往回传，我们都需要特征map为正值，所以修正线性的逆变换还是自己
3)反卷积，与BP的敏感项往回传类似，将卷积核转置然后与特征map卷积（卷积方式为“full”）

### 可视化中总结出来的一些观点

+ 特征可视化(网络特征的分成结构)：
第二层应对角落和其他边缘或者颜色的结合
第三层有更加复杂的不变性，捕捉到了相似的纹理
第四层显示了特定类间显著的差异性
第五层显示了有显著构成变化的整个物体

+ 特征演变过程
模型的底层在少数几个epoches就能收敛聚集，然而上层在一个相当多的epoches(40-50)之后才能有所变化
这显示了让模型完全训练到完全收敛的必要性

+ 特征不变性
小的变化对于模型的第一层都有非常大的影响，但对于最高层的影响却几乎没有
对于图像的平移、尺度、旋转的变化来说，网络的输出对于平移和尺度变化都是稳定的，但却不具有旋转不变性，除非目标图像时旋转对称的

+ 基于可视化做模型改善
可视化发现AlexNet第一层中有大量的高频和低频信息的混合，却几乎没有覆盖到中间的频率信息
且第二层中由于第一层卷积用的步长为4太大了，导致了有非常多的混叠情况
因此改变了AlexNet的第一层即将滤波器的大小11x11变成7x7，并且将步长4变成了2
这个改进使得低层得到更多的独特的特征以及更少的无意义的特征，高层的特征更加干净，清晰，保留了更多的第一层和第二层中的信息

+ 整个模型它自己清楚目标在图像中的具体位置吗？
通过一个方块挡住某一区域发现
如果图像中的目标被遮挡，那么被正确分类的概率会显著降低
这表明这种可视化与激发特征图的图像结构是真正对应上的，即大概能知道位置。

+ 在深度模型中如何对同一类物体的不同图像进行一致性分析
低层随机遮挡情况一致性分析较差，而第7层中，一致性较好
那是因为底层判别的是一类物体共有的部分（更注重细节），而高层判别的是类别中不同的品种这种更高维的部分了（更注重整体）。

### 实验

+ 保持模型的深度很重要。随意拿掉一层都会让准确率下降，奠定了深度对神经网络的重要性

【我的思考】
1.实现了神经网络每一层的可视化，从可视化着手分析，并以此改善模型，对未来的进一步研究有引导性作用
但是在网络结构本身没有做太多的修改，只是针对AlexNet做的简单的调整。



