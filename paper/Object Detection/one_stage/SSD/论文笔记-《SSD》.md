#SSD

#翻译：
http://noahsnail.com/2017/12/11/2017-12-11-Single%20Shot%20MultiBox%20Detector%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E4%B8%AD%E8%8B%B1%E6%96%87%E5%AF%B9%E7%85%A7/

### 概要
一种使用单个深度神经网络来检测图像中的目标的方法
对于300×300的输入，SSD在VOC2007测试中以59FPS的速度在Nvidia Titan X上达到74.3%的mAP


### 架构
相比于yolo，将全连接层替换为不同尺寸的全连接层，有点类似FPN的网络
在边界框上借鉴了faster rcnn的操作，只是在不同的尺寸特征上应用4个anchor
SSD方法的核心是使用小卷积滤波器来预测特征图上固定的一组默认边界框的类别分数和位置偏移，4个anchor相当于是在训练四个框的回归问题，与测试只要选择最佳的一个框即可
为了实现高检测精度，我们从不同尺度的特征图产生不同尺度的预测，并且通过宽高比来明确地分离预测

### 训练
训练SSD和训练使用region proposal、pooling的典型分类器的关键区别在于，真实标签信息需要被指定到固定的检测器输出集合中的某一特定输出。(因为是多尺寸预测)



### 思考

SSD最后对之前的方法做了对比：
目前有两种已建立的用于图像中对象检测的方法，一种基于滑动窗口，另一种基于region proposal分类。在卷积神经网络出现之前，用于检测的两种方法DeformablePart Model（DPM）[22]和选择性搜索[1]性能接近。
然而，在R-CNN[20]带来的显着改进之后，其结合了选择性搜索region proposal和基于卷积网络的后分类，region proposal对象检测方法变得普遍。

原始的R-CNN方法已经以各种方式进行了改进。第一组方法提高了后分类的质量和速度，因为它需要对成千上万的图像作物进行分类，这是昂贵和耗时的。SPPnet[9]对原始的R-CNN方法大大提速。
它引入了空间金字塔池化层，其对区域大小和尺度更加鲁棒，并且允许分类层重用在若干图像分辨率生成的特征图特征。Fast R-CNN[6]扩展了SPPnet，使得它可以通过最小化置信度和边界框回归的损失来对所有层进行端对端微调，
这在MultiBox[7]中首次引入用于学习对象。

第二组方法使用深层神经网络提高proposal生成的质量。在最近的工作中，例如MultiBox[7,8]，基于低层图像特征的选择性搜索region proposal被直接从单独的深层神经网络生成的proposal所替代。
这进一步提高了检测精度，但是导致了一些复杂的设置，需要训练两个神经网络及其之间的依赖。Faster R-CNN[2]通过从region proposal网络（RPN）中学习的方案替换了选择性搜索proposal，
并且引入了通过微调共享卷积层和两个网络的预测层之间交替来集成RPN与Fast R-CNN的方法。用这种方式region proposal池化中层特征图，最终分类步骤更快速。我们的SSD与Faster R-CNN中的region proposal网络（RPN）非常相似，
因为我们还使用固定的（默认）框来进行预测，类似于RPN中的achor框。但是，不是使用这些来池化特征和评估另一个分类器，我们同时在每个框中为每个对象类别产生一个分数。因此，我们的方法避免了将RPN与Fast R-CNN合并的复杂性，
并且更容易训练，更易于集成到其他任务中。

另一组方法与我们的方法直接相关，完全跳过proposal步骤，直接预测多个类别的边界框和置信度。 OverFeat[4]是滑动窗口方法的深度版本，在知道基础对象类别的置信度之后直接从最顶层特征图的每个位置预测边界框。
YOLO [5]使用整个最高层特征图来预测多个类别和边界框（这些类别共享）的置信度。我们的SSD方法属于此类别，因为我们没有提案步骤，但使用默认框。然而，我们的方法比现有方法更灵活，
因为我们可以在不同尺度的多个特征图中的每个特征位置上使用不同宽高比的默认框。如果顶层特征图每个位置只使用一个默认框，我们的SSD将具有与OverFeat[4]类似的架构;
如果我们使用整个顶层特征图并且添加一个全连接层用于预测而不是我们的卷积预测器，并且没有明确考虑多个宽高比，我们可以近似地再现YOLO[5]。